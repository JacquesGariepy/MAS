# ğŸš€ MAS Production System - Quick Start

## ğŸ“‹ DÃ©marrage en 3 Ã©tapes

### 1ï¸âƒ£ Cloner et configurer
```bash
git clone <repository-url>
cd mas-production-system
cp .env.example .env  # Pas besoin de modifier pour Ollama
```

### 2ï¸âƒ£ Lancer avec Docker (Ollama inclus)
```bash
docker-compose -f docker-compose.ollama.yml up -d
```

### 3ï¸âƒ£ VÃ©rifier que tout fonctionne
```bash
# API disponible sur
curl http://localhost:8000/health

# Documentation interactive
open http://localhost:8000/docs
```

## ğŸ¯ C'est tout !

L'application est maintenant prÃªte avec :
- âœ… API REST complÃ¨te
- âœ… Base de donnÃ©es PostgreSQL
- âœ… Cache Redis
- âœ… LLM Ollama (modÃ¨le llama2)
- âœ… Documentation Swagger

## ğŸ“ Structure simplifiÃ©e

```
mas-production-system/
â”œâ”€â”€ docker-compose.ollama.yml  # ğŸ³ Tout-en-un avec Ollama
â”œâ”€â”€ docker-compose.dev.yml     # ğŸ³ Pour OpenAI/LM Studio
â”œâ”€â”€ .env.example              # ğŸ“ Configuration template
â”œâ”€â”€ services/core/            # ğŸ’» Code source
â”‚   â”œâ”€â”€ src/                 # Code Python
â”‚   â”œâ”€â”€ tests/               # Tests
â”‚   â””â”€â”€ requirements.txt     # DÃ©pendances
â”œâ”€â”€ docs/                    # ğŸ“š Documentation
â””â”€â”€ config/                  # âš™ï¸ Configurations
```

## ğŸ”§ Commandes utiles

```bash
# Voir les logs
docker-compose -f docker-compose.ollama.yml logs -f

# ArrÃªter
docker-compose -f docker-compose.ollama.yml down

# Reset complet
docker-compose -f docker-compose.ollama.yml down -v
```

## ğŸ’¡ Prochaines Ã©tapes

1. Explorer l'API : http://localhost:8000/docs
2. CrÃ©er un agent : voir les exemples dans la doc Swagger
3. Lire la documentation complÃ¨te : `DEVELOPMENT.md`

## â“ Aide

- Configuration LLM : voir `LLM-SETUP.md`
- Guide Ollama : voir `OLLAMA-QUICKSTART.md`
- Configuration dÃ©taillÃ©e : voir `CONFIG-GUIDE.md`
- DÃ©veloppement : voir `DEVELOPMENT.md`