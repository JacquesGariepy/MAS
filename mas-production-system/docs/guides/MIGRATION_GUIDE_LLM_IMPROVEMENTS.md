# Guide de Migration : Am√©liorations du Service LLM et des Agents

## üéØ Objectif

Ce guide explique comment appliquer les am√©liorations d√©velopp√©es pour r√©soudre les probl√®mes de communication entre les agents et le LLM phi-4.

## üîç Probl√®mes R√©solus

### 1. **Timeouts et D√©connexions**
- ‚ùå Ancien : Timeout de 30 secondes causant des d√©connexions fr√©quentes
- ‚úÖ Nouveau : Timeouts adaptatifs (60s-600s) selon la complexit√© de la t√¢che

### 2. **Prompts Non Structur√©s**
- ‚ùå Ancien : Injection directe de JSON, pas de format clair
- ‚úÖ Nouveau : Templates structur√©s avec exemples et validation

### 3. **Gestion d'Erreur Faible**
- ‚ùå Ancien : √âchec complet en cas d'erreur
- ‚úÖ Nouveau : Retry intelligent, fallback, et r√©cup√©ration gracieuse

### 4. **R√©ponses Inconsistantes**
- ‚ùå Ancien : Format JSON non valid√©, r√©ponses vides
- ‚úÖ Nouveau : Validation de sch√©ma, r√©ponses structur√©es garanties

## üìã √âtapes de Migration

### √âtape 1 : Sauvegarder la Configuration Actuelle

```bash
# Sauvegarder les fichiers actuels
cd /mnt/c/Users/admlocal/Documents/source/repos/MAS/mas-production-system

# Cr√©er un dossier de backup
mkdir -p backups/$(date +%Y%m%d)

# Sauvegarder la configuration
cp config/config.yaml backups/$(date +%Y%m%d)/
cp services/core/src/services/llm_service.py backups/$(date +%Y%m%d)/
cp services/core/src/agents/types/*.py backups/$(date +%Y%m%d)/
```

### √âtape 2 : Appliquer la Nouvelle Configuration

```bash
# Remplacer la configuration
cp config/config_improved.yaml config/config.yaml

# V√©rifier les changements principaux
grep -E "timeout|retry|streaming" config/config.yaml
```

### √âtape 3 : Mettre √† Jour le Service LLM

```bash
# Remplacer le service LLM
cp services/core/src/services/llm_service_improved.py \
   services/core/src/services/llm_service.py

# Ou garder les deux versions en parall√®le pour tester
```

### √âtape 4 : Ajouter les Templates de Prompts

```bash
# Copier le fichier de templates
cp services/core/src/agents/templates.py \
   services/core/src/agents/templates.py
```

### √âtape 5 : Mettre √† Jour les Agents

#### Option A : Remplacement Complet (Recommand√© pour tests)

```bash
# Mettre √† jour l'agent hybride
cp services/core/src/agents/types/hybrid_agent_improved.py \
   services/core/src/agents/types/hybrid_agent.py

# Mettre √† jour l'agent cognitif
cp services/core/src/core/agents/cognitive_agent_improved.py \
   services/core/src/core/agents/cognitive_agent.py
```

#### Option B : Migration Progressive

```python
# Dans hybrid_agent.py, ajouter au d√©but :
from ..templates import build_agent_prompt, get_task_prompt
from ...services.llm_service_improved import ImprovedLLMService

# Modifier __init__ pour utiliser le service am√©lior√© :
def __init__(self, agent_data: Agent, db: AsyncSession):
    super().__init__(agent_data, db)
    self.llm_service = ImprovedLLMService()  # Au lieu de LLMService
```

### √âtape 6 : Mettre √† Jour les Variables d'Environnement

```bash
# Dans docker-compose.dev.yml, v√©rifier :
environment:
  - LLM_API_KEY=${LLM_API_KEY}
  - OPENAI_TIMEOUT=300  # Nouveau timeout par d√©faut
  - ENABLE_STREAMING=true
  - ADAPTIVE_TIMEOUTS=true
```

### √âtape 7 : Red√©marrer les Services

```bash
# Arr√™ter les services
docker-compose -f docker-compose.dev.yml down

# Reconstruire avec les nouvelles configurations
docker-compose -f docker-compose.dev.yml build --no-cache

# Red√©marrer
docker-compose -f docker-compose.dev.yml up -d

# V√©rifier les logs
docker-compose -f docker-compose.dev.yml logs -f core
```

## üß™ Tests de Validation

### Test 1 : V√©rifier les Timeouts

```bash
# Ex√©cuter le script de test
docker-compose -f docker-compose.dev.yml exec core \
  python /app/examples/test_improved_agents.py
```

### Test 2 : Tester avec une T√¢che Complexe

```bash
# Ex√©cuter la d√©mo am√©lior√©e
docker-compose -f docker-compose.dev.yml exec core \
  python /app/examples/mas_web_app_builder_demo_fixed.py
```

### Test 3 : V√©rifier les Logs LLM

```bash
# Surveiller les appels LLM
docker-compose -f docker-compose.dev.yml exec core \
  tail -f /app/logs/llm_requests.log | grep -E "timeout|retry|streaming"
```

## üìä M√©triques √† Surveiller

### Avant Migration
- Taux de timeout : ~30-40%
- Temps de r√©ponse moyen : Variable
- Taux d'erreur JSON : ~15%
- R√©ponses vides : Fr√©quentes

### Apr√®s Migration (Attendu)
- Taux de timeout : <5%
- Temps de r√©ponse moyen : Stable
- Taux d'erreur JSON : <2%
- R√©ponses vides : Rares

## üö® Rollback si N√©cessaire

Si des probl√®mes surviennent :

```bash
# Restaurer la configuration
cp backups/$(date +%Y%m%d)/config.yaml config/
cp backups/$(date +%Y%m%d)/llm_service.py services/core/src/services/
cp backups/$(date +%Y%m%d)/*.py services/core/src/agents/types/

# Red√©marrer
docker-compose -f docker-compose.dev.yml restart
```

## üìù Checklist de Migration

- [ ] Backup des fichiers actuels
- [ ] Application de la nouvelle configuration
- [ ] Mise √† jour du service LLM
- [ ] Ajout des templates de prompts
- [ ] Mise √† jour des agents (hybrid et cognitive)
- [ ] Configuration des variables d'environnement
- [ ] Rebuild des containers Docker
- [ ] Tests de validation
- [ ] Monitoring des m√©triques
- [ ] Documentation des changements

## üéØ B√©n√©fices Attendus

1. **Performance** : R√©duction drastique des timeouts
2. **Fiabilit√©** : R√©ponses consistantes et structur√©es
3. **Maintenabilit√©** : Prompts centralis√©s et r√©utilisables
4. **Debuggabilit√©** : Logs d√©taill√©s et tra√ßabilit√©
5. **Scalabilit√©** : Adaptation automatique √† la charge

## üí° Conseils

1. **Testez d'abord en d√©veloppement** avant la production
2. **Surveillez les logs** pendant les premi√®res heures
3. **Ajustez les timeouts** selon vos besoins sp√©cifiques
4. **Documentez tout changement** de configuration

## üÜò Support

En cas de probl√®me :
1. V√©rifier les logs : `docker-compose logs core`
2. Consulter les m√©triques : Port 9090
3. Revenir au backup si n√©cessaire
4. Ajuster les timeouts dans `config.yaml`

---

**Note** : Cette migration am√©liore significativement la robustesse du syst√®me. Les agents seront plus fiables et les communications avec le LLM plus stables.