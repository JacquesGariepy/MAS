#!/usr/bin/env python3
"""
Script pour afficher les m√©tadonn√©es LLM des t√¢ches et agents
"""

import subprocess
import json
from datetime import datetime

print("üîç ANALYSE DES M√âTADONN√âES LLM DANS LE SYST√àME MAS\n")
print("=" * 80)

# 1. Examiner la configuration des agents
print("\nü§ñ CONFIGURATION LLM DES AGENTS")
print("-" * 40)

sql_agents = """
SELECT 
    a.id,
    a.name,
    a.agent_type,
    a.configuration,
    a.beliefs,
    u.username as owner
FROM agents a
JOIN users u ON a.owner_id = u.id
WHERE a.is_active = true
ORDER BY a.created_at DESC
LIMIT 10;
"""

cmd = ["docker", "exec", "mas-production-system-db-1", "psql", "-U", "user", "-d", "mas", "-t", "-A", "-c", sql_agents]
result = subprocess.run(cmd, capture_output=True, text=True)

if result.returncode == 0:
    lines = result.stdout.strip().split('\n')
    for line in lines:
        parts = line.split('|')
        if len(parts) >= 6:
            agent_id = parts[0]
            name = parts[1]
            agent_type = parts[2]
            config = parts[3]
            beliefs = parts[4]
            owner = parts[5]
            
            print(f"\nü§ñ Agent: {name} ({agent_type})")
            print(f"   ID: {agent_id}")
            print(f"   Propri√©taire: {owner}")
            
            # Afficher la configuration LLM
            if config and config != '{}':
                try:
                    config_json = json.loads(config)
                    print("   üìã Configuration LLM:")
                    for key, value in config_json.items():
                        if key in ['temperature', 'model', 'provider', 'max_tokens', 'reasoning_depth']:
                            print(f"      - {key}: {value}")
                except:
                    print(f"   üìã Configuration: {config[:100]}...")
            else:
                print("   üìã Configuration: Par d√©faut (non personnalis√©e)")
            
            # Afficher les beliefs li√©es au LLM
            if beliefs and beliefs != '{}':
                try:
                    beliefs_json = json.loads(beliefs)
                    if any(k in beliefs_json for k in ['langue', 'domaine', 'style']):
                        print("   üß† Beliefs pertinentes:")
                        for key, value in beliefs_json.items():
                            if key in ['langue', 'domaine', 'style']:
                                print(f"      - {key}: {value}")
                except:
                    pass

# 2. Examiner les m√©tadonn√©es des t√¢ches
print("\n\nüìã M√âTADONN√âES LLM DES T√ÇCHES")
print("-" * 40)

sql_tasks = """
SELECT 
    t.id,
    t.title,
    t.task_type,
    t.status,
    t.task_metadata,
    t.result,
    a.name as agent_name,
    t.created_at,
    t.completed_at
FROM tasks t
LEFT JOIN agents a ON t.assigned_to = a.id
ORDER BY t.created_at DESC;
"""

cmd = ["docker", "exec", "mas-production-system-db-1", "psql", "-U", "user", "-d", "mas", "-t", "-A", "-c", sql_tasks]
result = subprocess.run(cmd, capture_output=True, text=True)

if result.returncode == 0:
    lines = result.stdout.strip().split('\n')
    for line in lines:
        parts = line.split('|')
        if len(parts) >= 9:
            task_id = parts[0]
            title = parts[1]
            task_type = parts[2]
            status = parts[3]
            task_metadata = parts[4]
            result = parts[5]
            agent_name = parts[6] if parts[6] else "Non assign√©"
            created_at = parts[7]
            completed_at = parts[8] if parts[8] else "En cours"
            
            print(f"\nüìå T√¢che: {title}")
            print(f"   ID: {task_id}")
            print(f"   Type: {task_type} | Status: {status}")
            print(f"   Agent: {agent_name}")
            
            # Afficher les m√©tadonn√©es de la t√¢che
            if task_metadata and task_metadata != '{}':
                try:
                    metadata_json = json.loads(task_metadata)
                    if metadata_json:
                        print("   üîß M√©tadonn√©es de t√¢che:")
                        for key, value in metadata_json.items():
                            print(f"      - {key}: {value}")
                except:
                    print(f"   üîß M√©tadonn√©es: {task_metadata[:100]}...")
            
            # Si la t√¢che est compl√©t√©e, examiner le r√©sultat
            if status == 'completed' and result:
                try:
                    result_json = json.loads(result)
                    if isinstance(result_json, dict):
                        print("   ‚úÖ R√©sultat avec m√©tadonn√©es:")
                        # Chercher les m√©tadonn√©es LLM dans le r√©sultat
                        llm_keys = ['model', 'provider', 'temperature', 'tokens_used', 
                                   'confidence', 'sources', 'timestamp', 'processing_time']
                        for key in llm_keys:
                            if key in result_json:
                                print(f"      - {key}: {result_json[key]}")
                except:
                    pass

# 3. Examiner les logs d'audit pour les appels LLM
print("\n\nüìä LOGS D'AUDIT LLM (si disponibles)")
print("-" * 40)

sql_audit = """
SELECT 
    action,
    details,
    created_at
FROM audit_logs
WHERE action LIKE '%llm%' OR action LIKE '%LLM%'
ORDER BY created_at DESC
LIMIT 10;
"""

cmd = ["docker", "exec", "mas-production-system-db-1", "psql", "-U", "user", "-d", "mas", "-t", "-A", "-c", sql_audit]
result = subprocess.run(cmd, capture_output=True, text=True)

if result.returncode == 0:
    lines = result.stdout.strip().split('\n')
    if lines and lines[0]:
        for line in lines:
            parts = line.split('|')
            if len(parts) >= 3:
                action = parts[0]
                details = parts[1]
                created_at = parts[2]
                
                print(f"\nüîç Action: {action}")
                print(f"   Date: {created_at}")
                if details:
                    try:
                        details_json = json.loads(details)
                        print("   D√©tails:")
                        for key, value in details_json.items():
                            print(f"      - {key}: {value}")
                    except:
                        print(f"   D√©tails: {details[:100]}...")
    else:
        print("   ‚ùå Aucun log d'audit LLM trouv√©")

# 4. Configuration actuelle du syst√®me
print("\n\n‚öôÔ∏è CONFIGURATION LLM ACTUELLE DU SYST√àME")
print("-" * 40)

# Lire les variables d'environnement depuis le conteneur
env_vars = ["LLM_PROVIDER", "LLM_MODEL", "LLM_TEMPERATURE", "LLM_MAX_TOKENS", "LLM_BASE_URL"]
print("Variables d'environnement dans le conteneur core:")

for var in env_vars:
    cmd = ["docker", "exec", "mas-production-system-core-1", "sh", "-c", f"echo ${var}"]
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode == 0:
        value = result.stdout.strip()
        if value:
            print(f"  {var}: {value}")
        else:
            print(f"  {var}: non d√©fini")

# 5. R√©sum√© des m√©tadonn√©es disponibles
print("\n\nüìà R√âSUM√â DES M√âTADONN√âES DISPONIBLES")
print("-" * 40)

print("""
Le syst√®me MAS stocke les m√©tadonn√©es LLM √† plusieurs niveaux:

1. **Configuration des agents** (table: agents, colonne: configuration)
   - temperature: Contr√¥le la cr√©ativit√© (0.0-1.0)
   - model: Mod√®le LLM sp√©cifique √† utiliser
   - provider: Provider LLM (openai, ollama, lmstudio)
   - max_tokens: Limite de tokens pour les r√©ponses
   - reasoning_depth: Profondeur du raisonnement
   - system_prompt: Prompt syst√®me personnalis√©

2. **M√©tadonn√©es des t√¢ches** (table: tasks, colonne: task_metadata)
   - Param√®tres de la requ√™te
   - Context de l'ex√©cution
   - R√©f√©rences aux agents

3. **R√©sultats des t√¢ches** (table: tasks, colonne: result)
   - response: La r√©ponse g√©n√©r√©e
   - confidence: Niveau de confiance (0.0-1.0)
   - sources: Sources d'information utilis√©es
   - timestamp: Horodatage de la g√©n√©ration
   - tokens_used: Nombre de tokens consomm√©s
   - processing_time: Temps de traitement

4. **Logs d'audit** (table: audit_logs)
   - Trace compl√®te des appels LLM
   - M√©triques de performance
   - Erreurs et r√©essais

5. **Variables d'environnement**
   - LLM_PROVIDER: Provider principal
   - LLM_MODEL: Mod√®le par d√©faut
   - LLM_TEMPERATURE: Temp√©rature par d√©faut
   - LLM_MAX_TOKENS: Limite de tokens
   - LLM_BASE_URL: URL de l'API
""")

print("\n" + "=" * 80)
print("‚ú® Analyse des m√©tadonn√©es termin√©e")