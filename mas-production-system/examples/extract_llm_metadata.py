#!/usr/bin/env python3
"""
Script pour extraire les m√©tadonn√©es LLM depuis une instance MAS en cours d'ex√©cution
"""

import requests
import json
import sys
from datetime import datetime
from typing import Dict, Any, List, Optional

API_URL = "http://localhost:8088"

def login(username: str = "test_user", password: str = "password123") -> Optional[str]:
    """Se connecter et obtenir un token"""
    try:
        response = requests.post(
            f"{API_URL}/auth/token",
            data={"username": username, "password": password}
        )
        if response.status_code == 200:
            return response.json()["access_token"]
    except Exception as e:
        print(f"Erreur de connexion: {e}")
    return None

def get_agents_llm_config(token: str) -> List[Dict[str, Any]]:
    """R√©cup√©rer la configuration LLM de tous les agents"""
    headers = {"Authorization": f"Bearer {token}"}
    agents_config = []
    
    try:
        # R√©cup√©rer la liste des agents
        response = requests.get(f"{API_URL}/api/v1/agents", headers=headers)
        if response.status_code == 200:
            agents_data = response.json()
            
            for agent in agents_data.get('items', []):
                agent_id = agent['id']
                
                # R√©cup√©rer les d√©tails complets de l'agent
                detail_response = requests.get(
                    f"{API_URL}/api/v1/agents/{agent_id}", 
                    headers=headers
                )
                
                if detail_response.status_code == 200:
                    details = detail_response.json()
                    
                    # Extraire la configuration LLM
                    config = {
                        "agent_id": agent_id,
                        "agent_name": agent['name'],
                        "agent_type": agent['agent_type'],
                        "role": agent['role'],
                        "status": agent['status'],
                        "llm_configuration": details.get('configuration', {}),
                        "beliefs": details.get('beliefs', {}),
                        "created_at": agent['created_at']
                    }
                    
                    # Chercher des infos LLM dans les beliefs
                    llm_beliefs = {k: v for k, v in details.get('beliefs', {}).items() 
                                  if any(term in k.lower() for term in ['llm', 'model', 'temperature', 'ai'])}
                    if llm_beliefs:
                        config['llm_from_beliefs'] = llm_beliefs
                    
                    agents_config.append(config)
                    
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des agents: {e}")
    
    return agents_config

def get_tasks_llm_metadata(token: str) -> List[Dict[str, Any]]:
    """R√©cup√©rer les m√©tadonn√©es LLM des t√¢ches"""
    headers = {"Authorization": f"Bearer {token}"}
    tasks_metadata = []
    
    try:
        # R√©cup√©rer la liste des t√¢ches
        response = requests.get(f"{API_URL}/api/v1/tasks", headers=headers)
        if response.status_code == 200:
            tasks_data = response.json()
            
            for task in tasks_data.get('items', []):
                task_id = task['id']
                
                # R√©cup√©rer les d√©tails de la t√¢che
                detail_response = requests.get(
                    f"{API_URL}/api/v1/tasks/{task_id}",
                    headers=headers
                )
                
                if detail_response.status_code == 200:
                    details = detail_response.json()
                    
                    # Extraire les m√©tadonn√©es LLM
                    metadata = details.get('task_metadata', {})
                    llm_metadata = {k: v for k, v in metadata.items()
                                   if any(term in str(k).lower() for term in ['llm', 'model', 'token', 'prompt', 'response'])}
                    
                    if llm_metadata or details.get('result'):
                        task_info = {
                            "task_id": task_id,
                            "title": task['title'],
                            "type": task['task_type'],
                            "status": task['status'],
                            "assigned_to": task.get('assigned_to'),
                            "llm_metadata": llm_metadata,
                            "result": details.get('result'),
                            "created_at": task['created_at']
                        }
                        tasks_metadata.append(task_info)
                        
    except Exception as e:
        print(f"Erreur lors de la r√©cup√©ration des t√¢ches: {e}")
    
    return tasks_metadata

def display_llm_metadata():
    """Afficher toutes les m√©tadonn√©es LLM extraites"""
    print("üîç EXTRACTION DES M√âTADONN√âES LLM DU SYST√àME MAS")
    print("=" * 70)
    
    # Se connecter
    token = login()
    if not token:
        print("\n‚ùå Impossible de se connecter √† l'API")
        print("   Assurez-vous que l'API est en cours d'ex√©cution avec:")
        print("   docker-compose up")
        return
    
    print("\n‚úÖ Connect√© avec succ√®s")
    
    # 1. Configuration des agents
    print("\n\nüì§ 1. CONFIGURATION LLM DES AGENTS")
    print("-" * 50)
    
    agents_config = get_agents_llm_config(token)
    
    if not agents_config:
        print("  Aucun agent trouv√©")
    else:
        for i, agent in enumerate(agents_config, 1):
            print(f"\n  Agent #{i}: {agent['agent_name']}")
            print(f"    Type: {agent['agent_type']}")
            print(f"    R√¥le: {agent['role']}")
            print(f"    Status: {agent['status']}")
            print(f"    ID: {agent['agent_id']}")
            
            if agent['llm_configuration']:
                print("    Configuration LLM:")
                for key, value in agent['llm_configuration'].items():
                    print(f"      - {key}: {value}")
            else:
                print("    Configuration LLM: Aucune (utilise les valeurs par d√©faut)")
            
            if agent.get('llm_from_beliefs'):
                print("    Infos LLM dans beliefs:")
                for key, value in agent['llm_from_beliefs'].items():
                    print(f"      - {key}: {value}")
    
    # 2. M√©tadonn√©es des t√¢ches
    print("\n\nüìä 2. M√âTADONN√âES LLM DES T√ÇCHES")
    print("-" * 50)
    
    tasks_metadata = get_tasks_llm_metadata(token)
    
    if not tasks_metadata:
        print("  Aucune t√¢che avec m√©tadonn√©es LLM trouv√©e")
    else:
        for i, task in enumerate(tasks_metadata, 1):
            print(f"\n  T√¢che #{i}: {task['title']}")
            print(f"    Type: {task['type']}")
            print(f"    Status: {task['status']}")
            print(f"    ID: {task['task_id']}")
            
            if task['llm_metadata']:
                print("    M√©tadonn√©es LLM:")
                for key, value in task['llm_metadata'].items():
                    if isinstance(value, (dict, list)):
                        print(f"      - {key}: {json.dumps(value, indent=8)}")
                    else:
                        print(f"      - {key}: {value}")
            
            if task['result'] and isinstance(task['result'], dict):
                # Chercher des infos LLM dans le r√©sultat
                llm_in_result = {k: v for k, v in task['result'].items()
                                if any(term in str(k).lower() for term in ['llm', 'model', 'token'])}
                if llm_in_result:
                    print("    Infos LLM dans le r√©sultat:")
                    for key, value in llm_in_result.items():
                        print(f"      - {key}: {value}")
    
    # 3. R√©sum√© des configurations
    print("\n\nüìà 3. R√âSUM√â DES CONFIGURATIONS LLM UTILIS√âES")
    print("-" * 50)
    
    # Collecter toutes les configurations uniques
    providers = set()
    models = set()
    temperatures = set()
    
    for agent in agents_config:
        config = agent['llm_configuration']
        if config.get('provider'):
            providers.add(config['provider'])
        if config.get('model'):
            models.add(config['model'])
        if config.get('temperature'):
            temperatures.add(config['temperature'])
    
    print(f"\n  Providers utilis√©s: {', '.join(providers) if providers else 'Aucun (utilise d√©faut)'}")
    print(f"  Mod√®les utilis√©s: {', '.join(models) if models else 'Aucun (utilise d√©faut)'}")
    print(f"  Temp√©ratures utilis√©es: {', '.join(map(str, temperatures)) if temperatures else 'Aucune (utilise d√©faut)'}")
    
    print("\n" + "=" * 70)
    print("‚úÖ Extraction termin√©e")

def export_llm_config(token: str, output_file: str = "llm_config_export.json"):
    """Exporter toute la configuration LLM dans un fichier JSON"""
    export_data = {
        "export_date": datetime.now().isoformat(),
        "agents": get_agents_llm_config(token),
        "tasks": get_tasks_llm_metadata(token)
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(export_data, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ Configuration export√©e dans: {output_file}")

def main():
    """Point d'entr√©e principal"""
    if len(sys.argv) > 1 and sys.argv[1] == "--export":
        token = login()
        if token:
            export_llm_config(token)
        else:
            print("‚ùå Impossible de se connecter pour l'export")
    else:
        display_llm_metadata()
        print("\nüí° Astuce: Utilisez --export pour exporter la configuration dans un fichier JSON")

if __name__ == "__main__":
    main()