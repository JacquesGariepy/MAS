#!/usr/bin/env python3
"""
Test direct de l'utilisation de LMStudio par un agent cognitif
"""

import asyncio
import aiohttp
import json
import time
import os

API_BASE_URL = "http://localhost:8000"
API_V1 = f"{API_BASE_URL}/api/v1"


async def main():
    print("="*80)
    print("ğŸ§ª TEST DIRECT LMSTUDIO - AGENT COGNITIF")
    print("="*80)
    
    async with aiohttp.ClientSession() as session:
        timestamp = int(time.time() * 1000) % 1000000
        
        # 1. CrÃ©er un utilisateur
        print("\nğŸ“‹ CrÃ©ation utilisateur...")
        user_data = {
            "username": f"test_llm_{timestamp}",
            "email": f"test_llm_{timestamp}@example.com",
            "password": "password123"
        }
        
        async with session.post(f"{API_BASE_URL}/auth/register", json=user_data) as resp:
            if resp.status in [200, 201]:
                print("âœ… Utilisateur crÃ©Ã©")
            else:
                print(f"âŒ Erreur: {await resp.text()}")
                return
                
        # 2. Login
        print("\nğŸ“‹ Connexion...")
        login_form = aiohttp.FormData()
        login_form.add_field('username', user_data["username"])
        login_form.add_field('password', user_data["password"])
        
        async with session.post(f"{API_BASE_URL}/auth/token", data=login_form) as resp:
            if resp.status == 200:
                auth_resp = await resp.json()
                token = auth_resp["access_token"]
                headers = {"Authorization": f"Bearer {token}"}
                print("âœ… Token obtenu")
            else:
                print(f"âŒ Erreur: {await resp.text()}")
                return
                
        # 3. CrÃ©er un agent cognitif
        print("\nğŸ“‹ CrÃ©ation agent cognitif...")
        agent_data = {
            "name": f"CognitiveTestLLM_{timestamp}",
            "agent_type": "reactive",  # Type cognitif
            "role": "assistant",
            "capabilities": ["reasoning", "analysis", "conversation"],
            "description": "Agent cognitif pour tester LMStudio"
        }
        
        async with session.post(f"{API_V1}/agents", json=agent_data, headers=headers) as resp:
            if resp.status in [200, 201]:
                agent_resp = await resp.json()
                agent_id = agent_resp["id"]
                print(f"âœ… Agent crÃ©Ã©: {agent_id}")
            else:
                print(f"âŒ Erreur: {await resp.text()}")
                return
                
        # 4. DÃ©marrer l'agent
        print("\nğŸ“‹ DÃ©marrage agent...")
        async with session.post(f"{API_V1}/agents/{agent_id}/start", headers=headers) as resp:
            if resp.status == 200:
                print("âœ… Agent dÃ©marrÃ©")
            else:
                print(f"âŒ Erreur: {await resp.text()}")
                
        # 5. Envoyer un message qui nÃ©cessite le LLM
        print("\nğŸ“‹ Test de communication avec LLM...")
        print("âš ï¸  SURVEILLEZ LMSTUDIO MAINTENANT!")
        
        # CrÃ©er un deuxiÃ¨me agent pour recevoir la rÃ©ponse
        agent2_data = {
            "name": f"ReceiverAgent_{timestamp}",
            "agent_type": "reflexive",
            "role": "receiver",
            "capabilities": ["receive"],
            "description": "Agent pour recevoir les messages"
        }
        
        async with session.post(f"{API_V1}/agents", json=agent2_data, headers=headers) as resp:
            if resp.status in [200, 201]:
                agent2_resp = await resp.json()
                agent2_id = agent2_resp["id"]
                print(f"âœ… Agent rÃ©cepteur crÃ©Ã©: {agent2_id}")
            else:
                print(f"âŒ Erreur: {await resp.text()}")
                return
                
        # Message qui force l'utilisation du LLM
        message_data = {
            "sender_id": agent_id,
            "receiver_id": agent2_id,
            "performative": "request",
            "content": {
                "action": "analyze",
                "query": "Explique-moi en dÃ©tail ce qu'est l'intelligence artificielle et donne 3 exemples concrets d'applications.",
                "require_reasoning": True
            }
        }
        
        print(f"\nğŸ“¨ Envoi message nÃ©cessitant raisonnement LLM...")
        print(f"   Question: {message_data['content']['query']}")
        
        async with session.post(
            f"{API_V1}/agents/{agent_id}/messages",
            json=message_data,
            headers=headers
        ) as resp:
            if resp.status in [200, 201]:
                msg_resp = await resp.json()
                print(f"âœ… Message envoyÃ©: {msg_resp['id']}")
            else:
                print(f"âŒ Erreur: {await resp.text()}")
                
        # 6. Attendre et vÃ©rifier la rÃ©ponse
        print("\nâ³ Attente du traitement (10 secondes)...")
        await asyncio.sleep(10)
        
        # VÃ©rifier les messages de l'agent cognitif
        print("\nğŸ“‹ VÃ©rification de l'activitÃ© de l'agent...")
        async with session.get(f"{API_V1}/agents/{agent_id}/messages", headers=headers) as resp:
            if resp.status == 200:
                messages = await resp.json()
                print(f"ğŸ“Š Messages de l'agent cognitif: {len(messages)}")
                
                for msg in messages:
                    if msg.get('performative') == 'inform' and 'response' in msg.get('content', {}):
                        print("\nğŸ¯ RÃ‰PONSE LLM TROUVÃ‰E!")
                        print(f"   Contenu: {msg['content']['response'][:200]}...")
                        
        # VÃ©rifier aussi l'Ã©tat du modÃ¨le
        print("\nğŸ§  Configuration LLM utilisÃ©e:")
        print(f"   Provider: {os.getenv('LLM_PROVIDER', 'unknown')}")
        print(f"   Model: {os.getenv('LLM_MODEL', 'unknown')}")
        print(f"   Base URL: {os.getenv('LLM_BASE_URL', 'unknown')}")
        
    print("\n" + "="*80)
    print("âœ… TEST TERMINÃ‰ - VÃ©rifiez LMStudio pour les requÃªtes!")
    print("="*80)


if __name__ == "__main__":
    asyncio.run(main())