# Configuration pour Docker Compose
# Copier ce fichier en .env et ajuster les valeurs

# ‚ö†Ô∏è IMPORTANT: Redis utilise le port 6380 au lieu de 6379 pour √©viter les conflits
# Si vous avez d√©j√† un Redis sur le port 6379, notre Redis utilise 6380

# Option 1 : OpenAI (Cloud - Payant)
# LLM_PROVIDER=openai
# LLM_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
# LLM_MODEL=gpt-4o-mini

# Option 2 : Ollama (Local - Gratuit) ü¶ô
LLM_PROVIDER=ollama
OLLAMA_MODEL=qwen3:4b

# Option 3 : LM Studio (Local - Gratuit)
# LLM_PROVIDER=lmstudio
# LLM_BASE_URL=http://host.docker.internal:1234/v1
# LLM_MODEL=local-model-name

# Configuration Redis (port modifi√© pour √©viter les conflits)
REDIS_EXTERNAL_PORT=6380

# Autres configurations (optionnel)
# SENTRY_DSN=https://xxx@sentry.io/xxx
# SLACK_WEBHOOK=https://hooks.slack.com/xxx